{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# ignore the overflow warnings\n",
    "np.seterr(over='ignore')\n",
    "\n",
    "#ignore the runtime warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of vectorized sms array set is:  (3000, 6277)\n"
     ]
    }
   ],
   "source": [
    "with open(\"train.csv\", \"r\", encoding='latin1') as train:\n",
    "    csvfile = pd.read_csv(train, header=None)\n",
    "\n",
    "csvfile = csvfile.values.tolist()\n",
    "\n",
    "labeltxt = []\n",
    "smstxt = []\n",
    "\n",
    "# store the label and the sms into two seperated list\n",
    "for line in csvfile:\n",
    "    labeltxt.append(line[0])\n",
    "    smstxt.append(line[1])\n",
    "\n",
    "labelnum = np.array([])\n",
    "\n",
    "# convert the 'ham' into 1, and 'spam' into 0\n",
    "for i in labeltxt:\n",
    "    if i == 'ham':\n",
    "        labelnum = np.append(labelnum, 1)\n",
    "    if i == 'spam':\n",
    "        labelnum = np.append(labelnum, 0)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "smsnum = vectorizer.fit_transform(smstxt).toarray()\n",
    "\n",
    "# ti-idf\n",
    "transformer = TfidfTransformer(smooth_idf=True)\n",
    "smstf = transformer.fit_transform(smsnum).toarray()\n",
    "\n",
    "print('the shape of vectorized sms array set is: ',smstf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a random value w0 from range(-1,6), as the initial weights\n",
    "since the loss function is convex and the weights w is unconstrained, I can start anywhere I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.randint(-1, 7, 6277, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define computing functions of the batch gradient descent\n",
    "for all the functions:\n",
    "y is the binary labels,\n",
    "x is the vectorized sms ndarray after tf-idf,\n",
    "w is the weight,\n",
    "lam is the lambda, the coefficient of the regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(w, x):\n",
    "    return 1/(1+np.exp(-(np.dot(x, w)), dtype=np.float128))\n",
    "\n",
    "# the derivative of sigmoid function respect to w\n",
    "def gradient_sigmoid(w, x):\n",
    "    return ((1/(2+np.exp(np.dot(x, w), dtype=np.float128) \n",
    "                + np.exp(-np.dot(x, w), dtype=np.float128))).reshape(len(x), 1))*x\n",
    "\n",
    "\n",
    "# the loss function with regularizer\n",
    "def loss(y, x, w, lam):\n",
    "    loss_compute = ((-y)*(np.log(sigmoid(w, x), dtype=np.float128))) \\\n",
    "                   - ((1-y)*(np.log(1-sigmoid(w, x), dtype=np.float128))) \\\n",
    "                   + (lam*np.power(np.linalg.norm(w), 2))\n",
    "    return sum(loss_compute)\n",
    "\n",
    "# the gradient of the loss function respect to w\n",
    "def gradient(y, x, w, lam):\n",
    "    y_col = y.reshape(1, len(y))\n",
    "    exp = (np.exp(-np.dot(x, w))).reshape(1, len(y))\n",
    "    g = np.dot((-y_col)*(1+exp), gradient_sigmoid(w, x)) + np.dot((1-y_col)*((1+exp)/exp), gradient_sigmoid(w, x))\n",
    "    g = (g.reshape(len(w),)) + 2*lam*w\n",
    "    return g\n",
    "\n",
    "# the batch gradient descent algorithm function \n",
    "# I set a fixed learning rate 0.3. \n",
    "def gradient_descent(w, x, y, lam):\n",
    "    w_old = w\n",
    "    step = 0.3\n",
    "    loss_old = loss(y, x, w_old, lam)\n",
    "    w_new = w_old - step*gradient(y, x, w_old, lam)\n",
    "    loss_new = loss(y, x, w_new, lam)\n",
    "\n",
    "    if loss_new - loss_old >= 0:\n",
    "        return w_old\n",
    "    else:\n",
    "        return gradient_descent(w_new, x, y, lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing start!\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1b94736744f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# implement the gradient descent algorithm to compute the weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# compute accuracy on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a3b0a9a02d88>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(w, x, y, lam)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m<ipython-input-4-a3b0a9a02d88>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(w, x, y, lam)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "# random shuffle all the emails and divide into 10 groups\n",
    "index = np.arange(3000)\n",
    "np.random.shuffle(index)\n",
    "index = index.reshape(10, 300)\n",
    "\n",
    "# initial several arrays for future use, to store the data\n",
    "test = np.zeros((300, 6277), dtype=np.float128)\n",
    "train = np.zeros((2700, 6277), dtype=np.float128)\n",
    "\n",
    "test_label = np.zeros(300, dtype=int)\n",
    "train_label = np.zeros(2700, dtype=int)\n",
    "\n",
    "lamda = np.array([])\n",
    "rate_test = np.array([])\n",
    "rate_train = np.array([])\n",
    "\n",
    "# iteration for the different lambda\n",
    "# the range of lambda I set is from (0.01, 0.2), with step 0.01\n",
    "print('computing start!')\n",
    "for i in range(0, 20):\n",
    "    lamda = np.append(lamda, 0.01+i*0.01)\n",
    "    rate_temp_test = 0\n",
    "    rate_temp_train = 0\n",
    "    \n",
    "    # 10-folds cross validation\n",
    "    for k in range(0, 10):\n",
    "        test_index = index[k]\n",
    "        train_index = np.delete(index, k, 0).reshape(2700)\n",
    "        \n",
    "        # construct the test set, with size of 300\n",
    "        ct = 0\n",
    "        for n in test_index:\n",
    "            test[ct] = smstf[n]\n",
    "            test_label[ct] = labelnum[n]\n",
    "            ct = ct + 1\n",
    "        \n",
    "        # construct the train set, with size of 2700\n",
    "        ct = 0\n",
    "        for n in train_index:\n",
    "            train[ct] = smstf[n]\n",
    "            train_label[ct] = labelnum[n]\n",
    "            ct = ct + 1\n",
    "        # implement the gradient descent algorithm to compute the weight\n",
    "        w0 = gradient_descent(w0, train, train_label, lamda[i])\n",
    "\n",
    "        # compute accuracy on test set\n",
    "        hit = 0\n",
    "        j = 0\n",
    "        for sms in test:\n",
    "            result = sigmoid(w0, sms)\n",
    "            if result >= 0.5:\n",
    "                result = 1\n",
    "            else:\n",
    "                result = 0\n",
    "\n",
    "            if result == test_label[j]:\n",
    "                hit = hit + 1\n",
    "            j = j + 1\n",
    "\n",
    "        rate_temp_test = rate_temp_test + hit/300\n",
    "\n",
    "        # compute accuracy on train set\n",
    "        hit = 0\n",
    "        j = 0\n",
    "        for sms in train:\n",
    "            result = sigmoid(w0, sms)\n",
    "            if result >= 0.5:\n",
    "                result = 1\n",
    "            else:\n",
    "                result = 0\n",
    "\n",
    "            if result == train_label[j]:\n",
    "                hit = hit + 1\n",
    "            j = j + 1\n",
    "\n",
    "        rate_temp_train = rate_temp_train + hit/2700\n",
    "\n",
    "    rate_test = np.append(rate_test, 100*(rate_temp_test/10))\n",
    "    rate_train = np.append(rate_train, 100*(rate_temp_train/10))\n",
    "    print('computing......',5*(i+1),'% complete')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('optimal average accuracy rate on test: ', np.amax(rate_test),'percentage')\n",
    "lamda_opt = lamda[np.argmax(rate_test)]\n",
    "print('optimal lambda is：', lamda_opt)\n",
    "\n",
    "# compute the optimal weight using the optimal lambda\n",
    "w_opt = gradient_descent(w0, smstf, labelnum, lamda_opt)\n",
    "# np.savez('w.npz', w_opt=w_opt)\n",
    "\n",
    "print('optimal loss is: ', loss(labelnum, smstf, w_opt, lamda_opt))\n",
    "\n",
    "# plot the curve of lambda versus accuracy\n",
    "plt.plot(lamda, rate_train, 'b', label='trainset accuracy')\n",
    "plt.plot(lamda, rate_test, 'r', label='testset accuracy')\n",
    "\n",
    "plt.ylabel('accuracy rate (percentage)')\n",
    "plt.xlabel('lambda')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model test\n",
    "Read the test.csv dataset, then use the optimal model w_opt to do test. Report the accuracy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.csv\", \"r\", encoding='latin1') as test:\n",
    "    testfile = pd.read_csv(test, header=None)\n",
    "\n",
    "testfile = testfile.values.tolist()\n",
    "\n",
    "labeltest = []\n",
    "smstest = []\n",
    "\n",
    "# store the label and the sms into two seperated list\n",
    "for line in testfile:\n",
    "    labeltest.append(line[0])\n",
    "    smstest.append(line[1])\n",
    "\n",
    "labeltestnum = np.array([])\n",
    "\n",
    "# convert the 'ham' into 1, and 'spam' into 0\n",
    "for i in labeltest:\n",
    "    if i == 'ham':\n",
    "        labeltestnum = np.append(labeltestnum, 1)\n",
    "    if i == 'spam':\n",
    "        labeltestnum = np.append(labeltestnum, 0)\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=True)\n",
    "\n",
    "ct = 0\n",
    "i = 0\n",
    "\n",
    "# count the number of right match.\n",
    "for sms in smstest:\n",
    "    \n",
    "    # apply the same dict to vectorize the test set\n",
    "    testarray = vectorizer.transform([sms]).toarray()\n",
    "    \n",
    "    # tf_idf transform\n",
    "    testarray = transformer.fit_transform(testarray).toarray()\n",
    "    \n",
    "    # compute the result of sigmoid function, using w_opt\n",
    "    result = sigmoid(w_opt, testarray)\n",
    "    \n",
    "    if result >= 0.5:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "\n",
    "    if result == labeltestnum[i]:\n",
    "        ct = ct + 1\n",
    "    \n",
    "    i = i+1\n",
    "\n",
    "print('the number of right match is:',ct)\n",
    "print('the accuracy rate is:',100*ct/len(labeltestnum), 'percentage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
