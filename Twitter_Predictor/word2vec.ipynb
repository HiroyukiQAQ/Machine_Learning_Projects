{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMPS242 HW5 Report\n",
    "## Team Member: Yunzhe Li(#1571061) & Yong Deng(#1571065)\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I: word2vec\n",
    "------------\n",
    "- In this section, we import the dataset 'train.csv' 'test.csv' and convert them into numerical vectors using library Spacy's wording embedding.\n",
    "- According to the official documentation of Spacy, its pre-trained build-in dictionary is actually from the GloVe with 300 dimensions per word vector, which I believe will greatly improve our accuracy.\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all the libraries I'll use in this section.\n",
    "## Here the 'en_vectors_web_lg' is the dictionary we will use.\n",
    "\n",
    "import pandas as pd\n",
    "import en_vectors_web_lg \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a funtion to read the .csv file and split the labels and tweets into two list.\n",
    "## Note that the labels of test.csv is None, thus we discard them directly.\n",
    "\n",
    "def csv_reading(f_name):\n",
    "    \n",
    "    with open(f_name, \"r\", encoding='utf8') as train:\n",
    "        csvfile = pd.read_csv(train)\n",
    "    \n",
    "    csvfile = csvfile.values.tolist()\n",
    "    \n",
    "    labels = [row[0] for row in csvfile]\n",
    "    twitters = [row[1] for row in csvfile]\n",
    "    \n",
    "    return labels, twitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the .csv file reading function\n",
    "\n",
    "train_labels, train_twitters = csv_reading('train.csv')\n",
    "_, test_twitters = csv_reading('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to remove all the urls at the end of each twitter.\n",
    "\n",
    "def remove_url(twitters):        \n",
    "    \n",
    "    twitters_iter = twitters.__iter__()\n",
    "        \n",
    "    for i in range(len(twitters)):\n",
    "        twitters[i] = twitters_iter.__next__().split('http')[0]    \n",
    "    \n",
    "    return twitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_twitters = remove_url(train_twitters)\n",
    "test_twitters = remove_url(test_twitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the Spacy dictionary to implement words embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dictionary\n",
    "\n",
    "nlp = en_vectors_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the word2vec function.\n",
    "## It will return a list of numpy ndarrays which has different length.\n",
    "## Each tweet will convert to a numpy array with shape [length, 300].\n",
    "\n",
    "def word2vec(twitters):\n",
    "    \n",
    "    twitters_vectors = [None]*len(twitters)     \n",
    "    \n",
    "    for i in range(len(twitters)):\n",
    "       \n",
    "        twitter_doc = nlp(twitters[i]) \n",
    "        twitter_vector = [None]*len(twitter_doc)\n",
    "       \n",
    "        for j in range(len(twitter_doc)):\n",
    "            twitter_vector[j] = twitter_doc[j].vector\n",
    "        \n",
    "        twitters_vectors[i] = twitter_vector    \n",
    "    \n",
    "    return twitters_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the word2vec function\n",
    "\n",
    "train_twitters = word2vec(train_twitters)\n",
    "test_twitters = word2vec(test_twitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the binary cases labels into 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the label 'HillaryClinton' to 0 and 'realDonaldTrump' to 1\n",
    "\n",
    "def numeric_label(labels):\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == 'HillaryClinton':\n",
    "            labels[i] = 0\n",
    "        elif labels[i] == 'realDonaldTrump':\n",
    "            labels[i] = 1\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = numeric_label(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save my embedding results into a .npz file for Section II use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('embedding_matrix.npz', train_matrix=train_twitters, test_matrix=test_twitters, train_labels=train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
